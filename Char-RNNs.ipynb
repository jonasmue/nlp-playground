{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Copy of RNNs.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyOvlrcB7eKqjpdK5/bB195F",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/jonasmue/nlp-playground/blob/master/Char-RNNs.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CNzDVC3whAxV",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import torch\n",
        "import os\n",
        "import numpy as np\n",
        "from torch import nn\n",
        "from google.colab import drive\n",
        "from torch import optim\n",
        "from tqdm import tqdm\n",
        "from time import time"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zcAb3DTWniSn",
        "colab_type": "text"
      },
      "source": [
        "# Data Preprocessing"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "twJ75Ixjnx2S",
        "colab_type": "code",
        "outputId": "e8e32125-def2-4c01-8c54-a5865a59f39e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "# Mount Google Drive (for now)\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QBb4rw9Un2pp",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "file_path = os.path.join(\"drive\", \"My Drive\", \"data\", \"himym.txt\")\n",
        "with open(file_path) as f:\n",
        "  lines = f.readlines()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "e4juqXtqoGqp",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "text = \"\".join(lines)\n",
        "#text = \"Dummy Text\""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qhNMQ7HiqHtF",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "char_set = list(set(text))\n",
        "char2id = {c:i for i,c in enumerate(char_set)}\n",
        "id2char = {i:c for i,c in enumerate(char_set)}"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JsI7_5tyqZrV",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "text_labels = [char2id[c] for c in text]\n",
        "num_characters = len(char2id)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_qwK9Gh6qjLs",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "num_characters = len(char2id)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "j2DcT7U-1jTD",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def get_next_training_batch(labels, num_chars, batch_size=32):\n",
        "  eye = np.eye(num_chars)\n",
        "  for i in range(0, len(labels) - 1, batch_size):\n",
        "    X = torch.Tensor(eye[labels[i:i + batch_size]]).cuda()\n",
        "    y = torch.Tensor(labels[i + 1:i + 1 + batch_size]).long().cuda()\n",
        "    if X.shape[0] < batch_size or y.shape[0] < batch_size:\n",
        "      return\n",
        "    yield X, y"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5fW6cqOChD3u",
        "colab_type": "text"
      },
      "source": [
        "# Implementation of GRU and LSTM using PyTorch\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7SA0bkp5Lwl5",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class GRU_Layer(nn.Module):\n",
        "  def __init__(self, num_characters, hidden_size, initial_state=None):\n",
        "    super().__init__()\n",
        "    self.hidden_size = hidden_size\n",
        "    self.num_characters = num_characters\n",
        "\n",
        "    # -- Init weight matrices\n",
        "    self.W_z = nn.Parameter(torch.randn((self.hidden_size, self.num_characters)))\n",
        "    self.W_r = nn.Parameter(torch.randn((self.hidden_size, self.num_characters)))\n",
        "    self.W_h = nn.Parameter(torch.randn((self.hidden_size, self.num_characters)))\n",
        "\n",
        "    self.U_z = nn.Parameter(torch.randn((self.hidden_size, self.hidden_size)))\n",
        "    self.U_r = nn.Parameter(torch.randn((self.hidden_size, self.hidden_size)))\n",
        "    self.U_h = nn.Parameter(torch.randn((self.hidden_size, self.hidden_size)))\n",
        "\n",
        "    self.W_y = nn.Parameter(torch.randn((self.num_characters, self.hidden_size)))\n",
        "\n",
        "    # -- Init biases\n",
        "    self.b_z = nn.Parameter(torch.zeros(self.hidden_size))\n",
        "    self.b_r = nn.Parameter(torch.zeros(self.hidden_size))\n",
        "    self.b_h = nn.Parameter(torch.zeros(self.hidden_size))\n",
        "    self.b_y = nn.Parameter(torch.zeros(self.num_characters))\n",
        "\n",
        "    self.h = initial_state\n",
        "\n",
        "    self._init_weights()\n",
        "\n",
        "  def _init_weights(self):\n",
        "        for param in self.parameters():\n",
        "            param.requires_grad_(True)\n",
        "            \n",
        "            if param.data.ndimension() >= 2:\n",
        "                nn.init.xavier_uniform_(param.data)\n",
        "            else:\n",
        "                nn.init.zeros_(param.data)\n",
        "\n",
        "  def forward(self, x_t):\n",
        "    if self.h is None:\n",
        "      self.h = torch.zeros(self.hidden_size).cuda()\n",
        "    \n",
        "    z_t = torch.sigmoid(self.W_z.matmul(x_t) + self.U_z.matmul(self.h) + self.b_z)\n",
        "    r_t = torch.sigmoid(self.W_r.matmul(x_t) + self.U_r.matmul(self.h) + self.b_r)\n",
        "    h_tilde = torch.tanh(self.W_h.matmul(x_t) + self.U_h.matmul(r_t * self.h) + self.b_h)\n",
        "    self.h = z_t * self.h + (1 - z_t) * h_tilde\n",
        "    y_hat = self.W_y.matmul(self.h) + self.b_y\n",
        "    return y_hat, self.h\n",
        "\n",
        "  "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ng6DbBV6hIr-",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class GRU(nn.Module):\n",
        "  def __init__(self, num_characters, n_layers=2, hidden_size=1024, initial_states=None):\n",
        "    super().__init__()\n",
        "    if initial_states is not None:\n",
        "      assert len(initial_states) == n_layers\n",
        "\n",
        "    self.n_layers = n_layers\n",
        "    layers_temp = []\n",
        "    \n",
        "    for i in range(n_layers):\n",
        "      initial_state = initial_states[i] if initial_states is not None else None\n",
        "      layer = GRU_Layer(num_characters, hidden_size, initial_state)\n",
        "      layers_temp.append(layer)\n",
        "    \n",
        "    self.layers = nn.ModuleList(layers_temp)\n",
        "\n",
        "  def forward(self, X):\n",
        "    Y_hat = torch.zeros_like(X)\n",
        "    hidden_states = []\n",
        "\n",
        "    for i, x_t in enumerate(X):\n",
        "      for layer in self.layers:\n",
        "        x_t, hidden_state = layer(x_t)\n",
        "        hidden_states.append(hidden_state)\n",
        "      Y_hat[i] = x_t\n",
        "    return torch.log_softmax(Y_hat, dim=1), hidden_states\n",
        "\n",
        "\n",
        "  def predict(self, initial_character_encoding, length_of_sequence=100):\n",
        "    curr_char = initial_character_encoding\n",
        "    predicted = [curr_char]\n",
        "\n",
        "    for i in range(length_of_sequence):\n",
        "      for layer in self.layers:\n",
        "        curr_char, _ = layer(curr_char)\n",
        "      predicted.append(curr_char)  \n",
        "    \n",
        "    return predicted"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "whG1TOR60Wzh",
        "colab_type": "text"
      },
      "source": [
        "---"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5MFdtLJu0QVs",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class LSTM_Layer(nn.Module):\n",
        "  def __init__(self, num_characters, hidden_size, initial_h=None, initial_C=None):\n",
        "    super().__init__()\n",
        "    self.hidden_size = hidden_size\n",
        "    self.num_characters = num_characters\n",
        "\n",
        "    # -- Init weight matrices\n",
        "    self.W_f = nn.Parameter(torch.randn((self.hidden_size, self.num_characters)))\n",
        "    self.W_i = nn.Parameter(torch.randn((self.hidden_size, self.num_characters)))\n",
        "    self.W_o = nn.Parameter(torch.randn((self.hidden_size, self.num_characters)))\n",
        "    self.W_C = nn.Parameter(torch.randn((self.hidden_size, self.num_characters)))\n",
        "\n",
        "    self.U_f = nn.Parameter(torch.randn((self.hidden_size, self.hidden_size)))\n",
        "    self.U_i = nn.Parameter(torch.randn((self.hidden_size, self.hidden_size)))\n",
        "    self.U_o = nn.Parameter(torch.randn((self.hidden_size, self.hidden_size)))\n",
        "    self.U_C = nn.Parameter(torch.randn((self.hidden_size, self.hidden_size)))\n",
        "\n",
        "    self.W_y = nn.Parameter(torch.randn((self.num_characters, self.hidden_size)))\n",
        "\n",
        "    # -- Init biases\n",
        "    self.b_f = nn.Parameter(torch.zeros(self.hidden_size))\n",
        "    self.b_i = nn.Parameter(torch.zeros(self.hidden_size))\n",
        "    self.b_o = nn.Parameter(torch.zeros(self.hidden_size))\n",
        "    self.b_C = nn.Parameter(torch.zeros(self.hidden_size))\n",
        "    self.b_y = nn.Parameter(torch.zeros(self.num_characters))\n",
        "\n",
        "    self.h = initial_h\n",
        "    self.C = initial_C\n",
        "\n",
        "    self._init_weights()\n",
        "\n",
        "  def _init_weights(self):\n",
        "        for param in self.parameters():\n",
        "            param.requires_grad_(True)\n",
        "            \n",
        "            if param.data.ndimension() >= 2:\n",
        "                nn.init.xavier_uniform_(param.data)\n",
        "            else:\n",
        "                nn.init.zeros_(param.data)\n",
        "\n",
        "  def forward(self, x_t):\n",
        "    if self.h is None:\n",
        "      self.h = torch.zeros(self.hidden_size).cuda()\n",
        "      self.C = torch.zeros(self.hidden_size).cuda()\n",
        "    \n",
        "    f_t = torch.sigmoid(self.W_f.matmul(x_t) + self.U_f.matmul(self.h) + self.b_f)\n",
        "    i_t = torch.sigmoid(self.W_i.matmul(x_t) + self.U_i.matmul(self.h) + self.b_i)\n",
        "    o_t = torch.sigmoid(self.W_o.matmul(x_t) + self.U_o.matmul(self.h) + self.b_o)\n",
        "\n",
        "    C_tilde_t = torch.tanh(self.W_C.matmul(x_t) + self.U_C.matmul(self.h) + self.b_C)\n",
        "    self.C = self.C * f_t + C_tilde_t * i_t\n",
        "    self.h = o_t * torch.tanh(self.C)\n",
        "\n",
        "    y_hat = self.W_y.matmul(self.h) + self.b_y\n",
        "    return y_hat, self.h, self.C\n",
        "\n",
        "  "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JJt4jZ5Z0RVL",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class LSTM(nn.Module):\n",
        "  def __init__(self, num_characters, n_layers=2, hidden_size=1024, initial_states=None):\n",
        "    super().__init__()\n",
        "    if initial_states is not None:\n",
        "      assert len(initial_states) == n_layers\n",
        "\n",
        "    self.n_layers = n_layers\n",
        "    layers_temp = []\n",
        "    \n",
        "    for i in range(n_layers):\n",
        "      initial_state = initial_states[i] if initial_states is not None else None\n",
        "      layer = LSTM_Layer(num_characters, hidden_size, initial_state)\n",
        "      layers_temp.append(layer)\n",
        "    \n",
        "    self.layers = nn.ModuleList(layers_temp)\n",
        "\n",
        "  def forward(self, X):\n",
        "    Y_hat = torch.zeros_like(X)\n",
        "    hidden_states = []\n",
        "\n",
        "    for i, x_t in enumerate(X):\n",
        "      for layer in self.layers:\n",
        "        x_t, hidden_state, cell_state = layer(x_t)\n",
        "        hidden_states.append(hidden_state)\n",
        "        hidden_states.append(cell_state)\n",
        "      Y_hat[i] = x_t\n",
        "    return torch.log_softmax(Y_hat, dim=1), hidden_states\n",
        "\n",
        "\n",
        "  def predict(self, initial_character_encoding, length_of_sequence=100):\n",
        "    curr_char = initial_character_encoding\n",
        "    predicted = [curr_char]\n",
        "\n",
        "    for i in range(length_of_sequence):\n",
        "      for layer in self.layers:\n",
        "        curr_char, _, _ = layer(curr_char)\n",
        "      predicted.append(curr_char)  \n",
        "    \n",
        "    return predicted"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CgrMBW2MD4-y",
        "colab_type": "code",
        "outputId": "a903c8fc-4be5-4f95-fa19-ea821ccaa933",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "training_data = text_labels[:len(text_labels) // 2]\n",
        "len(training_data)//32"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "41026"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PznSLiBJExhE",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#training_data = text_labels"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eGRc8GdthfB-",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "rnn = LSTM(num_characters, 1, 512).cuda()\n",
        "#rnn = nn.LSTM(input_size=num_characters, hidden_size=512)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "s7vUdlaeoepj",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "n_epochs = 5\n",
        "batch_size = 32\n",
        "criterion = torch.nn.CrossEntropyLoss()\n",
        "optimizer = optim.Adam(rnn.parameters(), lr=0.001)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EAPcBw92PSNG",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def prediction_to_string(prediction):\n",
        "  result = \"\"\n",
        "  for t in prediction:\n",
        "    result += id2char[torch.argmax(torch.softmax(t, dim=-1)).item()]\n",
        "  return result"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UOFVzrduofU7",
        "colab_type": "code",
        "outputId": "9733f7c4-f75c-4a8c-a2c3-679e1487ab1b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "for epoch in range(n_epochs):\n",
        "  start = time()\n",
        "  running_loss = 0\n",
        "  for i, batch in enumerate(get_next_training_batch(training_data, num_characters, batch_size)):\n",
        "    optimizer.zero_grad()\n",
        "    X, y = batch\n",
        "    #X = X.view([batch_size, 1, num_characters])\n",
        "    outputs, hidden_states = rnn(X)\n",
        "    loss = criterion(outputs, y)\n",
        "    loss.backward()\n",
        "\n",
        "    # Gradient Clipping\n",
        "    for param in rnn.parameters():\n",
        "      if param.grad is None:\n",
        "          continue\n",
        "      grad_val = torch.clamp(param.grad, -5, 5)\n",
        "    optimizer.step()\n",
        "    \n",
        "    for hidden in hidden_states:\n",
        "      hidden.detach_()\n",
        "\n",
        "    running_loss += loss.item()\n",
        "\n",
        "    if i and not i % 100:\n",
        "      print(\"\\n--------------------\\nLoss after iteration {}: {}\".format(i, running_loss))\n",
        "      print(\"Took {} seconds\".format(time() - start))\n",
        "      print(\"--------------------\")\n",
        "      print(\"Training Text:\", prediction_to_string(X))\n",
        "      start = time()\n",
        "      running_loss = 0\n",
        "      initial_char = \"D\"\n",
        "      initial_char_encoding = torch.Tensor(np.eye(num_characters)[char2id[initial_char]]).cuda()\n",
        "      prediction = rnn.predict(initial_char_encoding, 256)\n",
        "      print(\"--------------------\")\n",
        "      print(\"Sample Prediction:\", prediction_to_string(prediction))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\n",
            "--------------------\n",
            "Loss after iteration 100: 150.93116801977158\n",
            "Took 3.675058364868164 seconds\n",
            "--------------------\n",
            "Training Text: ame called... \"Have you met Ted?\n",
            "--------------------\n",
            "Sample Prediction: D.ttttttttttttttttttttttttttttttttttttttttttttttttttttttttttttttttttttttttttttttttttttttttttttttttttttttttttttttttttttttttttttttttttttttttttttttttttttttttttttttttttttttttttttttttttttttttttttttttttttttttttttttttttttttttttttttttttttttttttttttttttttttttttttttt\n",
            "\n",
            "--------------------\n",
            "Loss after iteration 200: 157.99454182386398\n",
            "Took 3.9156711101531982 seconds\n",
            "--------------------\n",
            "Training Text: l: (covers mouth) OH!\n",
            "Ted: Why a\n",
            "--------------------\n",
            "Sample Prediction: Ddttttttttttttttttttttttttttttttttttttttttttttttttttttttttttttttttttttttttttttttttttttttttttttttttttttttttttttttttttttttttttttttttttttttttttttttttttttttttttttttttttttttttttttttttttttttttttttttttttttttttttttttttttttttttttttttttttttttttttttttttttttttttttttttt\n",
            "\n",
            "--------------------\n",
            "Loss after iteration 300: 172.36598533391953\n",
            "Took 3.7934646606445312 seconds\n",
            "--------------------\n",
            "Training Text: e Freezes)\n",
            "Narrator: Son, a piec\n",
            "--------------------\n",
            "Sample Prediction: Dettttttttttttttttttttttttttttttttttttttttttttttttttttttttttttttttttttttttttttttttttttttttttttttttttttttttttttttttttttttttttttttttttttttttttttttttttttttttttttttttttttttttttttttttttttttttttttttttttttttttttttttttttttttttttttttttttttttttttttttttttttttttttttttt\n",
            "\n",
            "--------------------\n",
            "Loss after iteration 400: 174.48305314779282\n",
            "Took 3.880596399307251 seconds\n",
            "--------------------\n",
            "Training Text: t me at the bar in fifteen minut\n",
            "--------------------\n",
            "Sample Prediction: D ttttttttttttttttttttttttttttttttttttttttttttttttttttttttttttttttttttttttttttttttttttttttttttttttttttttttttttttttttttttttttttttttttttttttttttttttttttttttttttttttttttttttttttttttttttttttttttttttttttttttttttttttttttttttttttttttttttttttttttttttttttttttttttttt\n",
            "\n",
            "--------------------\n",
            "Loss after iteration 500: 182.36889958381653\n",
            "Took 3.812622308731079 seconds\n",
            "--------------------\n",
            "Training Text: \n",
            "(Ted presses the buzzer, dogs b\n",
            "--------------------\n",
            "Sample Prediction: Dottttttttttttttttttttttttttttttttttttttttttttttttttttttttttttttttttttttttttttttttttttttttttttttttttttttttttttttttttttttttttttttttttttttttttttttttttttttttttttttttttttttttttttttttttttttttttttttttttttttttttttttttttttttttttttttttttttttttttttttttttttttttttttttt\n",
            "\n",
            "--------------------\n",
            "Loss after iteration 600: 159.00007194280624\n",
            "Took 3.8238656520843506 seconds\n",
            "--------------------\n",
            "Training Text: ust go. (Gets up)\n",
            "Robin: Hold on\n",
            "--------------------\n",
            "Sample Prediction: D ttttttttttttttttttttttttttttttttttttttttttttttttttttttttttttttttttttttttttttttttttttttttttttttttttttttttttttttttttttttttttttttttttttttttttttttttttttttttttttttttttttttttttttttttttttttttttttttttttttttttttttttttttttttttttttttttttttttttttttttttttttttttttttttt\n",
            "\n",
            "--------------------\n",
            "Loss after iteration 700: 166.9134959578514\n",
            "Took 3.8079230785369873 seconds\n",
            "--------------------\n",
            "Training Text: own at Ted from her apartment wi\n",
            "--------------------\n",
            "Sample Prediction: Dhttttttttttttttttttttttttttttttttttttttttttttttttttttttttttttttttttttttttttttttttttttttttttttttttttttttttttttttttttttttttttttttttttttttttttttttttttttttttttttttttttttttttttttttttttttttttttttttttttttttttttttttttttttttttttttttttttttttttttttttttttttttttttttttt\n",
            "\n",
            "--------------------\n",
            "Loss after iteration 800: 156.3783832192421\n",
            "Took 3.8078203201293945 seconds\n",
            "--------------------\n",
            "Training Text:  bar]\n",
            "Lily: But that's part of h\n",
            "--------------------\n",
            "Sample Prediction: Dattttttttttttttttttttttttttttttttttttttttttttttttttttttttttttttttttttttttttttttttttttttttttttttttttttttttttttttttttttttttttttttttttttttttttttttttttttttttttttttttttttttttttttttttttttttttttttttttttttttttttttttttttttttttttttttttttttttttttttttttttttttttttttttt\n",
            "\n",
            "--------------------\n",
            "Loss after iteration 900: 184.37066984176636\n",
            "Took 3.822014093399048 seconds\n",
            "--------------------\n",
            "Training Text:  ya? Couldn't play the game like\n",
            "--------------------\n",
            "Sample Prediction: D ttttttttttttttttttttttttttttttttttttttttttttttttttttttttttttttttttttttttttttttttttttttttttttttttttttttttttttttttttttttttttttttttttttttttttttttttttttttttttttttttttttttttttttttttttttttttttttttttttttttttttttttttttttttttttttttttttttttttttttttttttttttttttttttt\n",
            "\n",
            "--------------------\n",
            "Loss after iteration 1000: 174.29913771152496\n",
            "Took 3.850952625274658 seconds\n",
            "--------------------\n",
            "Training Text: ppetite!\n",
            "Ted: I don't think so.\n",
            "\n",
            "--------------------\n",
            "Sample Prediction: Dattttttttttttttttttttttttttttttttttttttttttttttttttttttttttttttttttttttttttttttttttttttttttttttttttttttttttttttttttttttttttttttttttttttttttttttttttttttttttttttttttttttttttttttttttttttttttttttttttttttttttttttttttttttttttttttttttttttttttttttttttttttttttttttt\n",
            "\n",
            "--------------------\n",
            "Loss after iteration 1100: 159.16523545980453\n",
            "Took 3.8356614112854004 seconds\n",
            "--------------------\n",
            "Training Text:  had fun. Everybody wanged, ever\n",
            "--------------------\n",
            "Sample Prediction: Dattttttttttttttttttttttttttttttttttttttttttttttttttttttttttttttttttttttttttttttttttttttttttttttttttttttttttttttttttttttttttttttttttttttttttttttttttttttttttttttttttttttttttttttttttttttttttttttttttttttttttttttttttttttttttttttttttttttttttttttttttttttttttttttt\n",
            "\n",
            "--------------------\n",
            "Loss after iteration 1200: 172.70263040065765\n",
            "Took 3.825316905975342 seconds\n",
            "--------------------\n",
            "Training Text: f them\" she's the one.\n",
            "Barney: Y\n",
            "--------------------\n",
            "Sample Prediction: Duttttttttttttttttttttttttttttttttttttttttttttttttttttttttttttttttttttttttttttttttttttttttttttttttttttttttttttttttttttttttttttttttttttttttttttttttttttttttttttttttttttttttttttttttttttttttttttttttttttttttttttttttttttttttttttttttttttttttttttttttttttttttttttttt\n",
            "\n",
            "--------------------\n",
            "Loss after iteration 1300: 156.73554396629333\n",
            "Took 3.816467761993408 seconds\n",
            "--------------------\n",
            "Training Text: ain.\n",
            "Robin: (Imitates a rewindin\n",
            "--------------------\n",
            "Sample Prediction: D ttttttttttttttttttttttttttttttttttttttttttttttttttttttttttttttttttttttttttttttttttttttttttttttttttttttttttttttttttttttttttttttttttttttttttttttttttttttttttttttttttttttttttttttttttttttttttttttttttttttttttttttttttttttttttttttttttttttttttttttttttttttttttttttt\n",
            "\n",
            "--------------------\n",
            "Loss after iteration 1400: 157.4807527065277\n",
            "Took 4.006210565567017 seconds\n",
            "--------------------\n",
            "Training Text:  out of the window.)\n",
            "Barney: Get\n",
            "--------------------\n",
            "Sample Prediction: Dittttttttttttttttttttttttttttttttttttttttttttttttttttttttttttttttttttttttttttttttttttttttttttttttttttttttttttttttttttttttttttttttttttttttttttttttttttttttttttttttttttttttttttttttttttttttttttttttttttttttttttttttttttttttttttttttttttttttttttttttttttttttttttttt\n",
            "\n",
            "--------------------\n",
            "Loss after iteration 1500: 170.79698354005814\n",
            "Took 4.030218601226807 seconds\n",
            "--------------------\n",
            "Training Text: ..uh, did you just get in from D\n",
            "--------------------\n",
            "Sample Prediction: Dorttoooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooo\n",
            "\n",
            "--------------------\n",
            "Loss after iteration 1600: 168.73108446598053\n",
            "Took 4.039578676223755 seconds\n",
            "--------------------\n",
            "Training Text: s.\n",
            "Tatiana: I think Chris is goi\n",
            "--------------------\n",
            "Sample Prediction: Dattttttttttttttttttttttttttttttttttttttttttttttttttttttttttttttttttttttttttttttttttttttttttttttttttttttttttttttttttttttttttttttttttttttttttttttttttttttttttttttttttttttttttttttttttttttttttttttttttttttttttttttttttttttttttttttttttttttttttttttttttttttttttttttt\n",
            "\n",
            "--------------------\n",
            "Loss after iteration 1700: 163.1350809931755\n",
            "Took 4.044789791107178 seconds\n",
            "--------------------\n",
            "Training Text: er McNeil's office)\n",
            "Ted: Look, t\n",
            "--------------------\n",
            "Sample Prediction: Dattooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooo\n",
            "\n",
            "--------------------\n",
            "Loss after iteration 1800: 170.09605330228806\n",
            "Took 3.899578809738159 seconds\n",
            "--------------------\n",
            "Training Text: s?\n",
            "Lily: Ooh, I don't know. It w\n",
            "--------------------\n",
            "Sample Prediction: Datttoooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooo\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-31-42456aa9b377>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      6\u001b[0m     \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m     \u001b[0;31m#X = X.view([batch_size, 1, num_characters])\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m     \u001b[0moutputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhidden_states\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrnn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      9\u001b[0m     \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m     \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    548\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    549\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 550\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    551\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    552\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-12-bd53a44d2b31>\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, X)\u001b[0m\n\u001b[1;32m     21\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx_t\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     22\u001b[0m       \u001b[0;32mfor\u001b[0m \u001b[0mlayer\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlayers\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 23\u001b[0;31m         \u001b[0mx_t\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhidden_state\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcell_state\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlayer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_t\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     24\u001b[0m         \u001b[0mhidden_states\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhidden_state\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     25\u001b[0m         \u001b[0mhidden_states\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcell_state\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    548\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    549\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 550\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    551\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    552\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-11-731fb3b37cc9>\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x_t)\u001b[0m\n\u001b[1;32m     46\u001b[0m     \u001b[0mf_t\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msigmoid\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mW_f\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmatmul\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_t\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mU_f\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmatmul\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mh\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mb_f\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     47\u001b[0m     \u001b[0mi_t\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msigmoid\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mW_i\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmatmul\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_t\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mU_i\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmatmul\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mh\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mb_i\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 48\u001b[0;31m     \u001b[0mo_t\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msigmoid\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mW_o\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmatmul\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_t\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mU_o\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmatmul\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mh\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mb_o\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     49\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     50\u001b[0m     \u001b[0mC_tilde_t\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtanh\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mW_C\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmatmul\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_t\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mU_C\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmatmul\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mh\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mb_C\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "87ymyvh7wzPR",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "  "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2e5kT0AZudUg",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}